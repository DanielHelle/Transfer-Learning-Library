Namespace(root='data/office31', data='Office31', source=['A'], target=['W'], train_resizing='default', val_resizing='default', resize_size=224, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], no_hflip=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), arch='resnet50', bottleneck_dim=256, no_pool=False, scratch=False, trade_off=1.0, batch_size=16, lr=0.01, lr_gamma=0.001, lr_decay=0.75, momentum=0.9, weight_decay=0.001, workers=2, epochs=2, iters_per_epoch=1000, print_freq=100, seed=1, per_class_eval=False, log='logs/dann/Office31_A2W', phase='train')
/home/daniel/exjobb/Transfer-Learning-Library/examples/domain_adaptation/image_classification/dann.py:40: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
train_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
lr: 0.001
Epoch: [0][   0/1000]	Time  1.46 ( 1.46)	Data  0.01 ( 0.01)	Loss   4.37 (  4.37)	Cls Acc 0.0 (0.0)	Domain Acc 40.6 (40.6)
Epoch: [0][ 100/1000]	Time  0.29 ( 0.30)	Data  0.19 ( 0.18)	Loss   1.62 (  1.83)	Cls Acc 43.8 (58.3)	Domain Acc 96.9 (89.9)
Epoch: [0][ 200/1000]	Time  0.30 ( 0.30)	Data  0.20 ( 0.19)	Loss   2.15 (  1.59)	Cls Acc 56.2 (65.6)	Domain Acc 71.9 (87.1)
Epoch: [0][ 300/1000]	Time  0.29 ( 0.30)	Data  0.19 ( 0.19)	Loss   1.37 (  1.46)	Cls Acc 81.2 (70.3)	Domain Acc 71.9 (84.1)
Epoch: [0][ 400/1000]	Time  0.30 ( 0.30)	Data  0.20 ( 0.19)	Loss   1.04 (  1.39)	Cls Acc 87.5 (73.0)	Domain Acc 71.9 (81.8)
Epoch: [0][ 500/1000]	Time  0.31 ( 0.30)	Data  0.20 ( 0.19)	Loss   0.63 (  1.33)	Cls Acc 93.8 (75.3)	Domain Acc 78.1 (80.4)
Epoch: [0][ 600/1000]	Time  0.31 ( 0.30)	Data  0.20 ( 0.19)	Loss   0.84 (  1.28)	Cls Acc 100.0 (77.2)	Domain Acc 71.9 (79.1)
Epoch: [0][ 700/1000]	Time  0.33 ( 0.30)	Data  0.23 ( 0.20)	Loss   1.33 (  1.24)	Cls Acc 87.5 (78.5)	Domain Acc 62.5 (78.1)
Epoch: [0][ 800/1000]	Time  0.33 ( 0.31)	Data  0.22 ( 0.20)	Loss   1.67 (  1.21)	Cls Acc 62.5 (79.8)	Domain Acc 56.2 (76.9)
Epoch: [0][ 900/1000]	Time  0.33 ( 0.31)	Data  0.22 ( 0.20)	Loss   0.78 (  1.19)	Cls Acc 93.8 (80.9)	Domain Acc 75.0 (75.7)
Test: [ 0/50]	Time  0.692 ( 0.692)	Loss 1.3505e+00 (1.3505e+00)	Acc@1  43.75 ( 43.75)
 * Acc@1 76.855
lr: 0.0005946035575013606
Epoch: [1][   0/1000]	Time  0.12 ( 0.12)	Data  0.01 ( 0.01)	Loss   1.06 (  1.06)	Cls Acc 93.8 (93.8)	Domain Acc 46.9 (46.9)
Epoch: [1][ 100/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.71 (  0.98)	Cls Acc 87.5 (90.8)	Domain Acc 84.4 (66.2)
Epoch: [1][ 200/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.72 (  0.99)	Cls Acc 100.0 (90.1)	Domain Acc 71.9 (65.2)
Epoch: [1][ 300/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   1.17 (  0.97)	Cls Acc 87.5 (90.2)	Domain Acc 75.0 (66.2)
Epoch: [1][ 400/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.97 (  0.96)	Cls Acc 87.5 (90.9)	Domain Acc 78.1 (66.1)
Epoch: [1][ 500/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.90 (  0.95)	Cls Acc 93.8 (91.2)	Domain Acc 78.1 (66.0)
Epoch: [1][ 600/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.70 (  0.95)	Cls Acc 93.8 (91.3)	Domain Acc 78.1 (65.6)
Epoch: [1][ 700/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.80 (  0.95)	Cls Acc 93.8 (91.5)	Domain Acc 62.5 (65.1)
Epoch: [1][ 800/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.89 (  0.94)	Cls Acc 93.8 (91.7)	Domain Acc 56.2 (64.9)
Epoch: [1][ 900/1000]	Time  0.33 ( 0.33)	Data  0.22 ( 0.22)	Loss   0.97 (  0.94)	Cls Acc 93.8 (91.9)	Domain Acc 53.1 (64.6)
Test: [ 0/50]	Time  0.263 ( 0.263)	Loss 1.6685e+00 (1.6685e+00)	Acc@1  56.25 ( 56.25)
 * Acc@1 85.912
best_acc1 = 85.9
Test: [ 0/50]	Time  0.133 ( 0.133)	Loss 1.6685e+00 (1.6685e+00)	Acc@1  56.25 ( 56.25)
 * Acc@1 85.912
test_acc1 = 85.9
